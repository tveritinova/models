{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../object_detection/utils/visualization_utils.py:25: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/jet/var/python/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/jet/var/python/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/jet/var/python/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/jet/var/python/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n",
      "    handle._run()\n",
      "  File \"/jet/var/python/lib/python3.6/asyncio/events.py\", line 127, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-c0a2cee3c146>\", line 8, in <module>\n",
      "    from matplotlib import pyplot as plt\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/jet/var/python/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops, label_map_util, visualization_utils as vis_util\n",
    "\n",
    "if tf.__version__ < '1.4.0':\n",
    "  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!! MODIFY THIS !!!!!\n",
    "model = 'russian_signs_ssd'\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(model+'/fine_tuned_model/frozen_inference_graph.pb', 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!! MODIFY THIS !!!!!\n",
    "label_map = label_map_util.load_labelmap('russian_signs_data/label_map.pbtxt')\n",
    "NUM_CLASSES= 198 #20, 198\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_background_thumbnail(image, thumbnail_size):\n",
    "    background = Image.new('RGB', thumbnail_size, \"black\")    \n",
    "    source_image = image\n",
    "    source_image.thumbnail(thumbnail_size)\n",
    "    (w, h) = source_image.size\n",
    "    background.paste(source_image, (int((thumbnail_size[0] -w) / 2), int((thumbnail_size[1] - h) / 2 )))\n",
    "    return background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_inference_for_single_image(image):\n",
    "    image_expanded = np.expand_dims(image, 0)\n",
    "\n",
    "    # Run inference\n",
    "    #start = time.time()\n",
    "    (boxes, scores, classes, num) = \\\n",
    "        sess.run([detection_boxes, detection_scores, detection_classes, num_detections], \n",
    "                 feed_dict={image_tensor: image_expanded})\n",
    "    \n",
    "    #end = time.time()\n",
    "    #print(\"only session {}\".format(end-start))\n",
    "\n",
    "    # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "    #output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "    output_dict = {}\n",
    "    output_dict['detection_classes'] =  np.squeeze(classes).astype(np.uint8)\n",
    "    output_dict['detection_boxes'] =  np.squeeze(boxes)\n",
    "    output_dict['detection_scores'] =  np.squeeze(scores)\n",
    "    if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "        \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    " \n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(LABELS), activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../../')\n",
    "\n",
    "from russian_signs.get_data import get_data as get_data_russian\n",
    "from swedish_signs.get_data import get_data as get_data_swedish\n",
    "\n",
    "os.chdir('models/research/object_detection')\n",
    "\n",
    "# !!!!! MODIFY THIS !!!!!\n",
    "data = get_data_russian()\n",
    "LABELS = data['LABELS']\n",
    "all_images = data['images']\n",
    "input_shape = data['input_shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.random.choice(all_images, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect ground truth and model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0207ec030e81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mnum_detections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetection_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_detections:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        class_model = get_model()\n",
    "        # !!! MODIFY THIS !!!!\n",
    "        class_model.load_weights('../../../classify_croped_weights_russian')\n",
    "        \n",
    "        # Definite input and output Tensors for detection_graph\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        # Each box represents a part of the image where a particular object was detected.\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        # Each score represent how level of confidence for each of the objects.\n",
    "        # Score is shown on the result image, together with the class label.\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        \n",
    "        for image in images:\n",
    "            print(image['filename'])\n",
    "            img = Image.open(image['filename'])\n",
    "            image_np = load_image_into_numpy_array(img)\n",
    "\n",
    "            copy_image = image_np.copy()\n",
    "            copy_image_2 = image_np.copy()\n",
    "            copy_img = img.copy()\n",
    "\n",
    "            print(\"GROUND TRUTH\")\n",
    "\n",
    "            signs = image['signs']\n",
    "\n",
    "            boxes = np.array([[sign['ymin'], sign['xmin'], sign['ymax'], sign['xmax']] for sign in signs])\n",
    "            classes =  np.array([LABELS.index(sign['name'])+1 for sign in signs])\n",
    "            scores = np.array([1.0 for sign in signs])\n",
    "\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "              image_np,\n",
    "              boxes,\n",
    "              classes,\n",
    "              scores,\n",
    "              category_index,\n",
    "              use_normalized_coordinates=True,\n",
    "              line_thickness=3)\n",
    "\n",
    "            plt.figure(figsize=(20,20))\n",
    "            plt.imshow(image_np)\n",
    "            plt.show()\n",
    "\n",
    "            print(\"MODEL PREDICTIONS RAW\")\n",
    "            output_dict = run_inference_for_single_image(copy_image)\n",
    "            boxes = output_dict['detection_boxes']\n",
    "            classes = output_dict['detection_classes']\n",
    "            scores = output_dict['detection_scores']\n",
    "\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "              copy_image,\n",
    "              boxes,\n",
    "              classes,\n",
    "              scores,\n",
    "              category_index,\n",
    "              use_normalized_coordinates=True,\n",
    "              line_thickness=3)\n",
    "\n",
    "            plt.figure(figsize=(20,20))\n",
    "            plt.imshow(copy_image)\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"MODEL PREDICTIONS CLASS\")\n",
    "            output_dict = run_inference_for_single_image(copy_image_2)\n",
    "            boxes = output_dict['detection_boxes']\n",
    "            classes = output_dict['detection_classes']\n",
    "            scores = output_dict['detection_scores']\n",
    "            \n",
    "            classes = []\n",
    "\n",
    "            w, h = copy_img.size\n",
    "\n",
    "            for i, box in enumerate(boxes):\n",
    "\n",
    "                left = box[1] * w\n",
    "                top = box[0] * h\n",
    "                right = box[3] * w\n",
    "                bottom = box[2] * h\n",
    "\n",
    "                crop_img = copy_img.crop((left, top, right, bottom))\n",
    "                crop_img = crop_img.resize((input_shape[0], input_shape[1]))\n",
    "                crop_img = img_to_array(crop_img)\n",
    "                pred = class_model.predict(np.expand_dims(crop_img, axis=0))\n",
    "\n",
    "                classes.append(np.argmax(pred[0])+1)\n",
    "            classes = np.array(classes)\n",
    "\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "              copy_image_2,\n",
    "              boxes,\n",
    "              classes,\n",
    "              scores,\n",
    "              category_index,\n",
    "              use_normalized_coordinates=True,\n",
    "              line_thickness=3)\n",
    "\n",
    "            plt.figure(figsize=(20,20))\n",
    "            plt.imshow(copy_image_2)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "def get_preds(image_dict, use_classification_croped=False, box_scores_thres=0.6):\n",
    "    \n",
    "    image = Image.open(image_dict['filename'])\n",
    "    #image = black_background_thumbnail(image, (1280, 960))\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    \n",
    "    #start = time.time()\n",
    "    output_dict = run_inference_for_single_image(image_np)\n",
    "    #end = time.time()\n",
    "    \n",
    "    #print(\"all {}\".format(end-start))\n",
    "    \n",
    "    inds = output_dict['detection_scores'] > box_scores_thres\n",
    "    boxes = output_dict['detection_boxes'][inds]\n",
    "    scores = output_dict['detection_scores'][inds]\n",
    "    classes = output_dict['detection_classes'][inds]\n",
    "\n",
    "    if use_classification_croped:\n",
    "        classes = []\n",
    "\n",
    "        w, h = image.size\n",
    "\n",
    "        for i, box in enumerate(boxes):\n",
    "            \n",
    "            left = box[1] * w\n",
    "            top = box[0] * h\n",
    "            right = box[3] * w\n",
    "            bottom = box[2] * h\n",
    "\n",
    "            crop_img = image.crop((left, top, right, bottom))\n",
    "            crop_img = crop_img.resize((input_shape[0], input_shape[1]))\n",
    "            crop_img = img_to_array(crop_img)\n",
    "            pred = class_model.predict(np.expand_dims(crop_img, axis=0))\n",
    "\n",
    "            classes.append(np.argmax(pred[0])+1)\n",
    "        classes = np.array(classes)\n",
    "                \n",
    "    return boxes, scores, classes     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 17.719529151916504\n",
      "100 117.4406681060791\n",
      "200 115.10358500480652\n",
      "300 121.64576148986816\n",
      "400 121.41639375686646\n",
      "500 117.52361369132996\n",
      "600 112.57298827171326\n",
      "700 115.53066754341125\n",
      "800 108.85897421836853\n",
      "900 109.4376175403595\n",
      "1000 115.0607647895813\n",
      "1100 114.40808820724487\n",
      "1200 115.617258310318\n",
      "1300 114.59703183174133\n",
      "1400 119.73213529586792\n",
      "1500 120.45418095588684\n",
      "1600 118.28280186653137\n",
      "1700 115.30648946762085\n",
      "1800 117.72275876998901\n",
      "1900 113.3415675163269\n",
      "all predictions cnt: 565\n"
     ]
    }
   ],
   "source": [
    "all_detections     = [[None for i in range(len(LABELS))] for j in range(len(images))]\n",
    "all_annotations    = [[None for i in range(len(LABELS))] for j in range(len(images))]\n",
    "\n",
    "num_preds = 0\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        class_model = get_model()\n",
    "        # !!! MODIFY THIS !!!!\n",
    "        class_model.load_weights('../../../classify_croped_weights_russian')\n",
    "        # Definite input and output Tensors for detection_graph\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        # Each box represents a part of the image where a particular object was detected.\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        # Each score represent how level of confidence for each of the objects.\n",
    "        # Score is shown on the result image, together with the class label.\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        \n",
    "        for i, image_dict in enumerate(images):\n",
    "            boxes, scores, classes = get_preds(image_dict, use_classification_croped=True)\n",
    "            score_sort = np.argsort(-scores)\n",
    "            pred_labels = classes[score_sort]\n",
    "            pred_boxes  = boxes[score_sort]\n",
    "            scores = scores[score_sort]\n",
    "\n",
    "            if not (len(boxes) == len(scores) == len(classes)):\n",
    "                print(\"!!!!!!!!!!\")\n",
    "\n",
    "            if not (len(boxes) == len(pred_boxes)):\n",
    "                print(\"??????\")\n",
    "\n",
    "            num_preds += len(scores)\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(i, \"{}\".format(time.time() - start))\n",
    "                start = time.time()\n",
    "\n",
    "            new_pred_boxes = [None for i in range(len(pred_boxes))]\n",
    "\n",
    "            for ind in range(len(pred_boxes)):\n",
    "                new_pred_boxes[ind] = np.append(pred_boxes[ind], scores[ind])\n",
    "\n",
    "            pred_boxes = np.array(new_pred_boxes).copy()\n",
    "\n",
    "            #print(\"all preds cnt\", len(scores))\n",
    "\n",
    "            d1 = {}\n",
    "            for label in range(len(LABELS)):\n",
    "                d1[label] = pred_boxes[pred_labels == label+1]\n",
    "\n",
    "            cn_ = 0\n",
    "            for label in range(len(LABELS)):\n",
    "                all_detections[i][label] = d1[label].copy()\n",
    "                cn_ += len(all_detections[i][label])\n",
    "            #print(\"have\", cn_)\n",
    "\n",
    "            #print(all_detections[i])\n",
    "\n",
    "            annotations = [[sign['xmin'], sign['ymin'], sign['xmax'], sign['ymax']] for sign in image_dict['signs']]\n",
    "\n",
    "            d2 = {}\n",
    "\n",
    "            for label in range(len(LABELS)):\n",
    "                d2[label] = []\n",
    "                for ind,sign in enumerate(image_dict['signs']):\n",
    "                    if LABELS.index(sign['name']) == label:\n",
    "                        d2[label].append(annotations[ind])\n",
    "\n",
    "            for label in range(len(LABELS)):\n",
    "                all_annotations[i][label] = d2[label].copy()\n",
    "        \n",
    "print(\"all predictions cnt:\", num_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(len(images)):\n",
    "    for j in range(len(LABELS)):\n",
    "        cnt += len(all_detections[i][j])\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_detections_swedish_with_class\", \"w\") as f:\n",
    "    f.write(str(all_detections))\n",
    "    \n",
    "with open(\"all_annotations_swedish_with_class\", \"w\") as f:\n",
    "    f.write(str(all_annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap(a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
    "\n",
    "    iw = np.minimum(np.expand_dims(a[:, 2], axis=1), b[:, 2]) - np.maximum(np.expand_dims(a[:, 0], 1), b[:, 0])\n",
    "    ih = np.minimum(np.expand_dims(a[:, 3], axis=1), b[:, 3]) - np.maximum(np.expand_dims(a[:, 1], 1), b[:, 1])\n",
    "        \n",
    "    iw = np.maximum(iw, 0)\n",
    "    ih = np.maximum(ih, 0)\n",
    "\n",
    "    ua = np.expand_dims((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), axis=1) + area - iw * ih\n",
    "\n",
    "    ua = np.maximum(ua, np.finfo(float).eps)\n",
    "    \n",
    "    \n",
    "    intersection = iw * ih\n",
    "    return intersection / ua  \n",
    "    \n",
    "def compute_ap(recall, precision):\n",
    "    mrec = np.concatenate(([0.], recall, [1.]))\n",
    "    mpre = np.concatenate(([0.], precision, [0.]))\n",
    "\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start computing precisions\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "rejected prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "rejected prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "false prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "accepted prediction\n",
      "rejected prediction\n",
      "rejected prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "false prediction\n",
      "accepted prediction\n",
      "accepted prediction\n",
      "false prediction\n",
      "accepted prediction\n"
     ]
    }
   ],
   "source": [
    "print(\"start computing precisions\")\n",
    "        \n",
    "average_precisions = {}\n",
    "    \n",
    "iou_threshold = 0.2\n",
    "    \n",
    "for label in range(len(LABELS)):\n",
    "    \n",
    "    false_positives = np.zeros((0,))\n",
    "    true_positives  = np.zeros((0,))\n",
    "    scores          = np.zeros((0,))\n",
    "    num_annotations = 0\n",
    "    num_preds = 0\n",
    "\n",
    "    for i, image_dict in enumerate(images):\n",
    "        detections           = all_detections[i][label]\n",
    "        annotations          = all_annotations[i][label]\n",
    "        num_annotations     += len(annotations)\n",
    "        detected_annotations = []\n",
    "        num_preds += len(detections)\n",
    "        \n",
    "        #print(detections)\n",
    "        \n",
    "        for d in detections:\n",
    "            scores = np.append(scores, d[4])\n",
    "\n",
    "            if len(annotations) == 0:\n",
    "                print(\"false prediction\")\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives  = np.append(true_positives, 0)\n",
    "                continue\n",
    "\n",
    "            overlaps            = compute_overlap(np.expand_dims([d[1], d[0], d[3], d[2]], axis=0), annotations)\n",
    "            #print(overlaps)\n",
    "            assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "            max_overlap         = overlaps[0, assigned_annotation]\n",
    "            if max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n",
    "                print(\"accepted prediction\")\n",
    "                false_positives = np.append(false_positives, 0)\n",
    "                true_positives  = np.append(true_positives, 1)\n",
    "                detected_annotations.append(assigned_annotation)\n",
    "            else:\n",
    "                print(\"rejected prediction\")\n",
    "                false_positives = np.append(false_positives, 1)\n",
    "                true_positives  = np.append(true_positives, 0)\n",
    "                \n",
    "    #print(\"predictions cnt for\", label, \":\", num_preds)\n",
    "    \n",
    "    # no annotations -> AP for this class is 0 (is this correct?)\n",
    "    if num_annotations == 0:\n",
    "        average_precisions[label] = 0\n",
    "        continue\n",
    "    \n",
    "    # sort by score\n",
    "    indices         = np.argsort(-scores)\n",
    "    false_positives = false_positives[indices]\n",
    "    true_positives  = true_positives[indices]\n",
    "    \n",
    "    # compute false positives and true positives\n",
    "    false_positives = np.cumsum(false_positives)\n",
    "    true_positives  = np.cumsum(true_positives)\n",
    "\n",
    "    # compute recall and precision\n",
    "    recall    = true_positives / float(num_annotations)\n",
    "    precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "    # compute average precision\n",
    "    average_precision  = compute_ap(recall, precision)  \n",
    "    average_precisions[label] = average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0,\n",
       " 1: 0,\n",
       " 2: 0.092592592592592587,\n",
       " 3: 0.0,\n",
       " 4: 0.0,\n",
       " 5: 0.0,\n",
       " 6: 0,\n",
       " 7: 0.0,\n",
       " 8: 0.0,\n",
       " 9: 0.0,\n",
       " 10: 0.0,\n",
       " 11: 0.33333333333333331,\n",
       " 12: 0.0,\n",
       " 13: 0,\n",
       " 14: 0.0,\n",
       " 15: 0.18518518518518517,\n",
       " 16: 0.0,\n",
       " 17: 0,\n",
       " 18: 0,\n",
       " 19: 0.0,\n",
       " 20: 0.0,\n",
       " 21: 0.5643915939581573,\n",
       " 22: 0.5,\n",
       " 23: 0.0,\n",
       " 24: 0,\n",
       " 25: 0.45804195804195807,\n",
       " 26: 0.5,\n",
       " 27: 0,\n",
       " 28: 0,\n",
       " 29: 0.10000000000000001,\n",
       " 30: 0,\n",
       " 31: 0,\n",
       " 32: 0.0,\n",
       " 33: 0.0,\n",
       " 34: 0,\n",
       " 35: 0.0,\n",
       " 36: 0.21464019851116625,\n",
       " 37: 0.0,\n",
       " 38: 0.0,\n",
       " 39: 0.25,\n",
       " 40: 0.0,\n",
       " 41: 0.0,\n",
       " 42: 0.0,\n",
       " 43: 0,\n",
       " 44: 0.5,\n",
       " 45: 0.0,\n",
       " 46: 0,\n",
       " 47: 0,\n",
       " 48: 0,\n",
       " 49: 0.29166666666666669,\n",
       " 50: 0,\n",
       " 51: 0,\n",
       " 52: 0.0,\n",
       " 53: 0.0,\n",
       " 54: 0,\n",
       " 55: 0,\n",
       " 56: 0,\n",
       " 57: 0,\n",
       " 58: 0.32954545454545459,\n",
       " 59: 0.0,\n",
       " 60: 0.0,\n",
       " 61: 0.0,\n",
       " 62: 0,\n",
       " 63: 0,\n",
       " 64: 0,\n",
       " 65: 0,\n",
       " 66: 0,\n",
       " 67: 0,\n",
       " 68: 0.13333333333333333,\n",
       " 69: 0.39305326969497473,\n",
       " 70: 0,\n",
       " 71: 0,\n",
       " 72: 0.42291882291882293,\n",
       " 73: 0.015151515151515152,\n",
       " 74: 0.0,\n",
       " 75: 0.0,\n",
       " 76: 0,\n",
       " 77: 0,\n",
       " 78: 0.0,\n",
       " 79: 0.0,\n",
       " 80: 0.0,\n",
       " 81: 0,\n",
       " 82: 0.0,\n",
       " 83: 0,\n",
       " 84: 0.0,\n",
       " 85: 0,\n",
       " 86: 0.0,\n",
       " 87: 0,\n",
       " 88: 0,\n",
       " 89: 0.0,\n",
       " 90: 0,\n",
       " 91: 0,\n",
       " 92: 0.0,\n",
       " 93: 0,\n",
       " 94: 0.0,\n",
       " 95: 0.0,\n",
       " 96: 0,\n",
       " 97: 0.31372549019607848,\n",
       " 98: 0,\n",
       " 99: 0.20000000000000001,\n",
       " 100: 0.0,\n",
       " 101: 0.0,\n",
       " 102: 0.25,\n",
       " 103: 0,\n",
       " 104: 0,\n",
       " 105: 0,\n",
       " 106: 0,\n",
       " 107: 0,\n",
       " 108: 0,\n",
       " 109: 0,\n",
       " 110: 0,\n",
       " 111: 0,\n",
       " 112: 0,\n",
       " 113: 0.6051235988052055,\n",
       " 114: 0.10526315789473684,\n",
       " 115: 0,\n",
       " 116: 0.0,\n",
       " 117: 0.0,\n",
       " 118: 0.31111111111111106,\n",
       " 119: 0.0,\n",
       " 120: 0,\n",
       " 121: 0.0,\n",
       " 122: 0.0,\n",
       " 123: 0,\n",
       " 124: 0,\n",
       " 125: 0,\n",
       " 126: 0.0,\n",
       " 127: 0,\n",
       " 128: 0.0,\n",
       " 129: 0,\n",
       " 130: 0.0,\n",
       " 131: 0.0,\n",
       " 132: 0,\n",
       " 133: 0.0,\n",
       " 134: 0.25,\n",
       " 135: 0,\n",
       " 136: 0.12820512820512819,\n",
       " 137: 0.0,\n",
       " 138: 0,\n",
       " 139: 0,\n",
       " 140: 0,\n",
       " 141: 0.33333333333333331,\n",
       " 142: 0.0,\n",
       " 143: 0.20000000000000001,\n",
       " 144: 0.0,\n",
       " 145: 0.0,\n",
       " 146: 0.0,\n",
       " 147: 0.0,\n",
       " 148: 0,\n",
       " 149: 0,\n",
       " 150: 0.0,\n",
       " 151: 0,\n",
       " 152: 0.0,\n",
       " 153: 0.0,\n",
       " 154: 0.023809523809523808,\n",
       " 155: 0,\n",
       " 156: 0,\n",
       " 157: 0,\n",
       " 158: 0.0,\n",
       " 159: 0,\n",
       " 160: 0.5,\n",
       " 161: 0.26666666666666666,\n",
       " 162: 0,\n",
       " 163: 0,\n",
       " 164: 0,\n",
       " 165: 0,\n",
       " 166: 0,\n",
       " 167: 0,\n",
       " 168: 0,\n",
       " 169: 0,\n",
       " 170: 0,\n",
       " 171: 0.0,\n",
       " 172: 0.29145732904400129,\n",
       " 173: 0.0,\n",
       " 174: 0,\n",
       " 175: 0.0,\n",
       " 176: 0.0,\n",
       " 177: 0,\n",
       " 178: 0.05128205128205128,\n",
       " 179: 0.0,\n",
       " 180: 0.2857142857142857,\n",
       " 181: 0,\n",
       " 182: 0.0,\n",
       " 183: 0.18928571428571428,\n",
       " 184: 0.0,\n",
       " 185: 0.59999999999999998,\n",
       " 186: 0.0,\n",
       " 187: 0,\n",
       " 188: 0,\n",
       " 189: 0,\n",
       " 190: 0,\n",
       " 191: 0,\n",
       " 192: 0.0,\n",
       " 193: 0.0,\n",
       " 194: 0,\n",
       " 195: 0.10000000000000001,\n",
       " 196: 1.0,\n",
       " 197: 0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
